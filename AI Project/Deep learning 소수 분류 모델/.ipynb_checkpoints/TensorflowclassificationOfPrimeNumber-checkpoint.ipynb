{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\young hwa\\.conda\\envs\\heawon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\young hwa\\.conda\\envs\\heawon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\young hwa\\.conda\\envs\\heawon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\young hwa\\.conda\\envs\\heawon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\young hwa\\.conda\\envs\\heawon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\young hwa\\.conda\\envs\\heawon\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "DataList=[]\n",
    "p=0\n",
    "n=0\n",
    "m1=0\n",
    "m2=20000\n",
    "for i in range(m1,m2):\n",
    "    k=int(math.sqrt(i)//1)+1\n",
    "    if i==0 or i==1:\n",
    "        n=1\n",
    "    for j in range(2,k):\n",
    "        if i%j==0:\n",
    "            n+=1\n",
    "            break\n",
    "    if n==0:\n",
    "        p=1\n",
    "    DataList.append([i,p])\n",
    "    p=0\n",
    "    n=0\n",
    "    \n",
    "\n",
    "DataList0=[]\n",
    "p=0\n",
    "n=0\n",
    "m3=20000\n",
    "m4=24000\n",
    "for i in range(m3,m4):\n",
    "    k=int(math.sqrt(i)//1)+1\n",
    "    for j in range(2,k):\n",
    "        if i%j==0:\n",
    "            n+=1\n",
    "            break\n",
    "    if n==0:\n",
    "        p=1\n",
    "    DataList0.append([i,p])\n",
    "    p=0\n",
    "    n=0\n",
    "    \n",
    "DataList=np.transpose(DataList)\n",
    "DataList0=np.transpose(DataList0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputDataLIst=[]\n",
    "list1=[]\n",
    "for i in range( len(DataList[0]) ):\n",
    "    for j in range(784):\n",
    "        list1.append(DataList[0][i])\n",
    "    InputDataLIst.append(list1)\n",
    "    list1=[]\n",
    "    \n",
    "InputDataLIst0=[]\n",
    "list1=[]\n",
    "for i in range( len(DataList0[0]) ):\n",
    "    for j in range(784):\n",
    "        list1.append(DataList0[0][i])\n",
    "    InputDataLIst0.append(list1)\n",
    "    list1=[]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train=np.array(InputDataLIst)\n",
    "y_train=np.array(DataList[1])\n",
    "x_test=np.array(InputDataLIst0)\n",
    "y_test=np.array(DataList0[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val  = x_train[int(m2*8/10):m2]\n",
    "x_train = x_train[0:int(m2*8/10)]\n",
    "y_val  = y_train[int(m2*8/10):m2]\n",
    "y_train = y_train[0:int(m2*8/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 2])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x):\n",
    "    # hidden layer1\n",
    "    w1 = tf.Variable(tf.random_uniform([784,256]))\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    h1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "    # hidden layer2\n",
    "    w2 = tf.Variable(tf.random_uniform([256,128]))\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "    h2_drop = tf.nn.dropout(h2, keep_prob)\n",
    "    # output layer\n",
    "    w3 = tf.Variable(tf.random_uniform([128,2]))\n",
    "    b3 = tf.Variable(tf.zeros([2]))\n",
    "    logits= tf.matmul(h2_drop, w3) + b3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits=logits, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# train hyperparameters\n",
    "epoch_cnt = 5\n",
    "batch_size = int(len(x_train)/10)\n",
    "iteration = int(len(x_train) // batch_size)\n",
    "\n",
    "earlystop_threshold = 5\n",
    "earlystop_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train acc: 0.883625, val acc: 0.9\n",
      "epoch: 1, train acc: 0.8835625, val acc: 0.9\n",
      "epoch: 2, train acc: 0.8835625, val acc: 0.9\n",
      "epoch: 3, train acc: 0.8835625, val acc: 0.9\n",
      "epoch: 4, train acc: 0.8835625, val acc: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    prev_train_acc = 0.0\n",
    "    max_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epoch_cnt):\n",
    "        avg_loss = 0.\n",
    "        start = 0; end = batch_size\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            _, loss = sess.run([train_op, loss_op], \n",
    "                               feed_dict={x: x_train[start: end], \n",
    "                                          y: y_train[start: end], \n",
    "                                          keep_prob: 0.9})\n",
    "            start = batch_size * (i+1) ; end = batch_size * (i+2)\n",
    "            # Compute train average loss\n",
    "            avg_loss += loss / iteration\n",
    "            \n",
    "        # Validate model\n",
    "        preds = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "        correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        # train accuracy\n",
    "        cur_train_acc = accuracy.eval({x: x_train, y: y_train,keep_prob: 1.0})\n",
    "        # validation accuarcy\n",
    "        cur_val_acc = accuracy.eval({x: x_val, y: y_val, keep_prob: 1.0})\n",
    "        # validation loss\n",
    "        cur_val_loss = loss_op.eval({x: x_val, y: y_val,keep_prob: 1.0})\n",
    "        \n",
    "        print(\"epoch: \"+str(epoch)+\n",
    "              \", train acc: \" + str(cur_train_acc) +\n",
    "              \", val acc: \" + str(cur_val_acc) )\n",
    "              #', train loss: '+str(avg_loss)+\n",
    "              #', val loss: '+str(cur_val_loss))\n",
    "        \n",
    "        if cur_val_acc < max_val_acc:\n",
    "            if cur_train_acc > prev_train_acc or cur_train_acc > 0.99:\n",
    "                if earlystop_cnt == earlystop_threshold:\n",
    "                    print(\"early stopped on \"+str(epoch))\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"overfitting warning: \"+str(earlystop_cnt))\n",
    "                    earlystop_cnt += 1\n",
    "            else:\n",
    "                earlystop_cnt = 0\n",
    "        else:\n",
    "            earlystop_cnt = 0\n",
    "            max_val_acc = cur_val_acc\n",
    "            # Save the variables to file.\n",
    "            save_path = saver.save(sess, \"model/model.ckpt\")\n",
    "        prev_train_acc = cur_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n",
      "[Test Accuracy] : 0.8985\n"
     ]
    }
   ],
   "source": [
    "# Start testing\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"model/model.ckpt\")\n",
    "    correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"[Test Accuracy] :\", accuracy.eval({x: x_test, y: y_test, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
